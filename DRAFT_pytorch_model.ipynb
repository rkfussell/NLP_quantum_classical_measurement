{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d573812-ab18-4a53-bedb-60465efe7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import WeightedRandomSampler  ## TODO come back here and implement with WeightedRandomSampler\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "import calibration_fns as cal\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, balanced_accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "150a4523-0c8d-42e9-bd1b-73698bb55abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "data_folder = cwd + '/Raw_labeled_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf6741c-f065-4ea5-b67f-81795682450a",
   "metadata": {},
   "source": [
    "### Step 1. Set up dataset for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4824622-d0bd-425f-a3b3-3021a37ff057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, val, test= du.getData(dataDir=dataDir, holdoutDir=holdoutDir,ValCutoff=ValCutoff)\n",
    "data = pd.read_excel(data_folder + 'sources.xlsx')\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data[\"Response\"] = data[\"Response\"].astype(str)\n",
    "data[\"code\"] = data[\"code\"].astype(str)\n",
    "\n",
    "train_size = int(0.7*len(data))\n",
    "val_size = int(0.15*len(data))\n",
    "train_data = data[:train_size]\n",
    "base_data = data[train_size:train_size + val_size]\n",
    "target_data = data[train_size + val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff5196e4-7b31-49f3-942f-f59e00ef5196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2029"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa699325-f222-4dda-ab6c-397cd3223844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(tokenizer, train):\n",
    "    all_sent = np.array(train.Response.values)\n",
    "    # Encode data\n",
    "    encoded_sentences = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_sent]\n",
    "    # Find the maximum length\n",
    "    max_len = max([len(sent) for sent in encoded_sentences])\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6625551e-1c27-4e77-bce0-bcd33eb97b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "MAX_LEN = get_max_len(tokenizer, train_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fd33fdc-9016-42a9-be52-3b5bccb01d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "print(MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38cc0fb4-bce8-4c53-ab10-ead576e5de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing_simple(text):\n",
    "    try:\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    except:\n",
    "        pass\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "427f03e9-41da-4bac-b5ad-9fe574e7b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_for_bert(data, tokenizer, max_len):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing_simple(str(sent)),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=max_len,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e2c059d-e65e-45c0-9c04-81491b51c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourcesDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.data, self.masks = preprocessing_for_bert(df[\"Response\"], tokenizer, MAX_LEN)\n",
    "        self.text = df[\"Response\"].reset_index(drop=True)\n",
    "        labels_enc, unique_labels = pd.factorize(df[\"code\"], sort = True)\n",
    "        self.labels = torch.tensor(labels_enc, dtype = torch.long)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        mask = self.masks[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, mask, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f19e1f75-63d9-4611-8a97-61c9028398a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_enc, unique_labels = pd.factorize(train_data[\"code\"], sort = True)\n",
    "target_to_class = {i:unique_labels[i] for i in range(len(unique_labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be21d0d6-c258-48f2-b89e-1734d82cc66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'L', 1: 'O', 2: 'P', 3: 'S'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52873860-b0ca-421c-b025-6628d68f923f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/rkf33/.conda/envs/labnotes7/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2829: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/rkf33/.conda/envs/labnotes7/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2829: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/rkf33/.conda/envs/labnotes7/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2829: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SourcesDataset(train_data, tokenizer, MAX_LEN)\n",
    "base_dataset = SourcesDataset(base_data, tokenizer, MAX_LEN)\n",
    "target_dataset = SourcesDataset(target_data, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7c2e009-d995-4d92-a17a-64d2ba99b95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2029"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "934801b2-4bfb-4548-b278-2e02ad48caa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  101,  2493,  9854, 19721,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0]),\n",
       " tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee235eaf-a2e3-4887-a275-cf043859b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, mask, label in train_dataset:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b21649a3-1978-4e72-b88c-db8def5876f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = train_data.code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62809b40-ffb4-4df4-9d1f-9910aae7ba16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3458687/3474696145.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  class_weights[1] = class_weights[1] / 4 # underweight \"other\"\n",
      "/tmp/ipykernel_3458687/3474696145.py:3: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  class_weights[1] = class_weights[1] / 4 # underweight \"other\"\n",
      "/tmp/ipykernel_3458687/3474696145.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  class_weights = torch.tensor(class_weights, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "#sample_weights = [1.0 / class_counts[i] for i in train_data.code.values]\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights[1] = class_weights[1] / 4 # underweight \"other\"\n",
    "sample_weights = [class_weights[i] for i in train_data.code.values]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "train_sampler=WeightedRandomSampler(sample_weights,len(train_dataset), replacement=True)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 16, sampler = train_sampler)\n",
    "base_dataloader = DataLoader(base_dataset, batch_size = 16) \n",
    "target_dataloader = DataLoader(target_dataset, batch_size = 16) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7046292f-4b2e-48b8-9ab9-c58840a183e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code\n",
       "L    1564\n",
       "O     292\n",
       "P     109\n",
       "S      64\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afcffdc4-1afa-40b2-ac93-6b6f970a35db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sents, masks, labels in train_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0eac15d-c8ec-44ca-ae97-7c72d79c1880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 2, 3, 0, 2, 2, 2, 0, 0, 3, 3, 3, 0, 3, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents.shape\n",
    "masks.shape\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797f8d52-de3b-40f2-90b2-b33b9b288d3b",
   "metadata": {},
   "source": [
    "### Step 2. Set up Pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7d37605-a89f-4772-b3a2-5c41def5305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourcesClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4, freeze_bert = False):\n",
    "        #Where we define all the parts of the model\n",
    "        super(SourcesClassifier, self).__init__()  # initialize object with everything from the parent class\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 200, num_classes\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Connect these parts and return the output\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20193fc5-ac40-4f8d-a2e5-4e770a789af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SourcesClassifier(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SourcesClassifier(num_classes = 4)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3155d3b5-bd08-456b-ae7d-41eba04b163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_out = model(sents, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ca746a4-70e1-46b3-a69b-77a9f2ecad46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_out.shape #batch size, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61f0ed0f-3265-4ac8-a3e4-1e174268cb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0012,  0.0348,  0.1257,  0.0572],\n",
       "        [-0.1234,  0.0328,  0.1113,  0.0786],\n",
       "        [-0.0341, -0.0613,  0.2232,  0.1021],\n",
       "        [ 0.0527, -0.0694,  0.1471,  0.0087],\n",
       "        [-0.0214,  0.0036,  0.1372,  0.0850],\n",
       "        [-0.0883,  0.0122,  0.0492,  0.1432],\n",
       "        [-0.0512, -0.0277,  0.0803,  0.1230],\n",
       "        [ 0.0236, -0.0752,  0.1647,  0.1728],\n",
       "        [-0.0175, -0.0021,  0.0675,  0.0321],\n",
       "        [-0.0996,  0.0564,  0.1316,  0.0434],\n",
       "        [-0.1605, -0.0508,  0.0461,  0.2130],\n",
       "        [-0.0141, -0.0624,  0.0920,  0.0654],\n",
       "        [-0.0199,  0.0047,  0.0725,  0.1541],\n",
       "        [-0.0512, -0.0008,  0.1165,  0.1073],\n",
       "        [-0.0891, -0.0759,  0.0570,  0.1501],\n",
       "        [-0.0675,  0.0302,  0.1174, -0.0403]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d342bab5-6e8a-4186-979b-d96fa783b2a1",
   "metadata": {},
   "source": [
    "### Step 3. The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acef84e5-c648-4254-8ce7-4d42aa40b94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available()  else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f38979e-ae58-46de-b089-892f0a504937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d69f394-a0ef-42de-b78a-83354263bc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3056, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(example_out, labels) # check that the loss function calculates. It won't be any good yet because we haven't done training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd370686-4cd9-4771-92f0-fe3e0d4eefaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 2, 3, 0, 2, 2, 2, 0, 0, 3, 3, 3, 0, 3, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "017b8966-ebf2-4fd6-9e3e-040c22cf49da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.bert.pooler.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a6d42be-9583-4cee-850d-116a302e16ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in model.modules():\n",
    "    if isinstance(module, torch.nn.LayerNorm):\n",
    "        module.eval()  # Set LayerNorm to eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e2b3dde-1454-4225-a05f-83127522108a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(sents, masks) \u001b[38;5;66;03m# get our outputs by calling the forward method on the images\u001b[39;00m\n\u001b[1;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# this is where we do backpropagation on the model to update the model weights\u001b[39;00m\n\u001b[1;32m     33\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m) \n\u001b[1;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.conda/envs/labnotes7/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/labnotes7/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/labnotes7/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 7\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "\n",
    "model = SourcesClassifier(num_classes=4)\n",
    "model.to(device)\n",
    "\n",
    "total_steps = len(train_dataloader) * num_epochs # Total number of training steps\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay = 1e-5)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "    print(\"-\"*70)\n",
    "    running_loss = 0.0\n",
    "    t0_epoch, t0_batch = time.time(), time.time()\n",
    "    total_loss, batch_loss, batch_counts = 0, 0, 0 # Reset tracking variables at the beginning of each epoch\n",
    "    model.train() # Set the model to train\n",
    "    for batch_idx, (sents, masks, labels) in enumerate(train_dataloader): \n",
    "        batch_counts +=1\n",
    "        sents, masks, labels = sents.to(device), masks.to(device), labels.to(device)\n",
    "        optimizer.zero_grad() # set our optimizer to zero_grad\n",
    "        outputs = model(sents, masks) # get our outputs by calling the forward method on the images\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward() # this is where we do backpropagation on the model to update the model weights\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        #print(f\"Batch {batch_idx}: Loss = {loss.item()}\")\n",
    "        batch_loss += loss.item()\n",
    "        running_loss += loss.item() * sents.size(0)\n",
    "        # Print the loss values and time elapsed for every 20 batches\n",
    "        if (batch_idx % 20 == 0 and batch_idx != 0) or (batch_idx == len(train_dataloader) - 1):\n",
    "            # Calculate time elapsed for 20 batches\n",
    "            time_elapsed = time.time() - t0_batch\n",
    "            # Print training results\n",
    "            print(f\"{epoch + 1:^7} | {batch_idx:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "    batch_loss, batch_counts = 0, 0\n",
    "    t0_batch = time.time()\n",
    "    train_loss = running_loss / len(train_dataloader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    val_accuracy = []\n",
    "    with torch.no_grad(): #to make sure the model weights are not touched\n",
    "        for sents, masks, labels in base_dataloader:\n",
    "            sents, masks, labels = sents.to(device), masks.to(device), labels.to(device)\n",
    "            outputs = model(sents, masks)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            running_loss += loss.item() * sents.size(0)\n",
    "            # Get the predictions\n",
    "            preds = torch.argmax(outputs, dim=1).flatten()\n",
    "            # Calculate the accuracy rate\n",
    "            accuracy = (preds == labels).cpu().numpy().mean() * 100\n",
    "            val_accuracy.append(accuracy)\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "    val_loss = running_loss / len(base_dataloader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    #Print epoch stats\n",
    "    print(f\"{epoch+1:^7} | {'-':^7} | {train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a9be0-95c5-411a-9def-c2855233b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss over epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef62cee-5341-4c3a-911c-9c840e715562",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model=model.to(device)\n",
    "all_logits = []\n",
    "all_labels = []\n",
    "# For each batch in our test set...\n",
    "for sents, masks, labels in base_dataloader:\n",
    "    sents, masks = sents.to(device), masks.to(device)\n",
    "    # Compute logits\n",
    "    with torch.no_grad():\n",
    "        logits = model(sents, masks)\n",
    "        all_logits.append(logits)\n",
    "        all_labels.append(labels)\n",
    "# Concatenate logits from each batch\n",
    "all_logits = torch.cat(all_logits, dim=0)\n",
    "all_labels = torch.cat(all_labels, dim = 0).cpu().numpy()\n",
    "# Apply softmax to calculate probabilities\n",
    "probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "preds = torch.argmax(all_logits, dim=1).flatten().cpu().numpy()\n",
    "all_logits = all_logits.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18df5cf-cd30-4254-9c60-427bcc03dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_LOPS = list(pd.Series(preds).map(target_to_class))\n",
    "print(\"L: \" + str(preds_LOPS.count(\"L\")))\n",
    "print(\"P: \" + str(preds_LOPS.count(\"P\")))\n",
    "print(\"S: \" + str(preds_LOPS.count(\"S\")))\n",
    "print(\"O: \" + str(preds_LOPS.count(\"O\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9306291d-3553-43a1-b26b-c8f12aeb5afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate metrics\n",
    "\n",
    "acc = accuracy_score(all_labels, preds)\n",
    "p = precision_score(all_labels, preds, average = None)\n",
    "r = recall_score(all_labels, preds, average = None)\n",
    "bal = balanced_accuracy_score(all_labels,preds)\n",
    "f1 = f1_score(all_labels,preds, average = None)\n",
    "\n",
    "print(acc)\n",
    "print(p)\n",
    "print(r)\n",
    "print(bal)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdded334-7d14-4f98-8060-2b8a5c699bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calibration phase: calculate a calibration curve. along with a base classifier density, we can get the base joint density and estimate the base prevalence\n",
    "\n",
    "print(\"Base dataset: number of samples in each category\")\n",
    "base_labels =list(pd.Series(base_dataset.labels.numpy()).map(target_to_class))\n",
    "print(\"L: \" + str(base_labels.count(\"L\")))\n",
    "print(\"P: \" + str(base_labels.count(\"P\")))\n",
    "print(\"S: \" + str(base_labels.count(\"S\")))\n",
    "print(\"O: \" + str(base_labels.count(\"O\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abe4493-96ed-4522-86b6-153068610094",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logits\n",
    "probs = F.softmax(all_logits, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4f360c-1bb9-4293-9446-15a85158d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {\"probs_L\": probs[:,0], \"probs_O\": probs[:,1], \"probs_P\": probs[:,2], \"probs_S\": probs[:,3], \"gt_label\":list(pd.Series(all_labels.cpu().numpy()).map(target_to_class)), \"text\":list(base_dataset.text.values)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b7285b-eef0-43ec-9fd8-6cda972b90a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f91b0a-93f6-4a3f-a561-49130f2ac5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"probs_L\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc28f9c-a3de-4551-9c6d-b879147d5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, sharey=True, tight_layout=True)\n",
    "axs.hist(df[\"probs_L\"], bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bd8271-dded-460d-875a-04ba65d19d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_cal_curve = cal.generate_calibration_curve_binned(df, num_bin = 10, code = \"L\", other_codes = [\"O\",\"P\",\"S\"])\n",
    "binned_cal_curve.plot(show_diagonal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a652964b-0e63-4e0c-b7bc-24782280e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {\"probs_L\": probs[:,0], \"probs_O\": probs[:,1], \"probs_P\": probs[:,2], \"probs_S\": probs[:,3], \"gt_label\":list(pd.Series(all_labels.cpu().numpy()).map(target_to_class)), \"text\":list(base_dataset.text.values)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd462f68-a04c-4929-9656-7e2db6c10b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "platt_cal_curve = cal.generate_calibration_curve_platt(df, code = \"L\", other_codes = [\"O\",\"P\",\"S\"])\n",
    "platt_cal_curve.plot(show_diagonal=True, error_score = \"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c266b64-53a3-475d-8ec5-6c0a5e0bc83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrapolation phase: run probabilistic estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d965590c-8b25-4b95-8d74-14d9e6b0d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model=model.to(device)\n",
    "all_logits = []\n",
    "all_labels = []\n",
    "# For each batch in our test set...\n",
    "for sents, masks, labels in target_dataloader:\n",
    "    sents, masks = sents.to(device), masks.to(device)\n",
    "    # Compute logits\n",
    "    with torch.no_grad():\n",
    "        logits = model(sents, masks)\n",
    "        all_logits.append(logits)\n",
    "        all_labels.append(labels)\n",
    "# Concatenate logits from each batch\n",
    "all_logits = torch.cat(all_logits, dim=0)\n",
    "all_labels = torch.cat(all_labels, dim = 0)\n",
    "# Apply softmax to calculate probabilities\n",
    "probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "preds = torch.argmax(all_logits, dim=1).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318cbd88-fb0c-4047-b2f2-a7b8651d7a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {\"probs_L\": probs[:,0], \"probs_O\": probs[:,1], \"probs_P\": probs[:,2], \"probs_S\": probs[:,3], \"gt_label\":list(pd.Series(all_labels.cpu().numpy()).map(target_to_class)), \"text\":list(target_dataset.text.values)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a299614-d4fd-41f2-9c8b-59336ac7cac6",
   "metadata": {},
   "source": [
    "## Calibration curves for L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc82cd-00f2-48db-bd61-d9adc53104d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, sharey=True, tight_layout=True)\n",
    "axs.hist(df[\"probs_L\"], bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a46f2-e9fa-4ff6-a916-75e1fa3b948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {\"probs_L\": probs[:,0], \"probs_O\": probs[:,1], \"probs_P\": probs[:,2], \"probs_S\": probs[:,3], \"gt_label\":list(pd.Series(all_labels.cpu().numpy()).map(target_to_class)), \"text\":list(target_dataset.text.values)})\n",
    "binned_cal_curve = cal.generate_calibration_curve_binned(df, num_bin = 10, code = \"L\", other_codes = [\"O\",\"P\",\"S\"])\n",
    "binned_cal_curve.plot(show_diagonal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f6c75-1467-4244-8579-22cdae6aa34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {\"probs_L\": probs[:,0], \"probs_O\": probs[:,1], \"probs_P\": probs[:,2], \"probs_S\": probs[:,3], \"gt_label\":list(pd.Series(all_labels.cpu().numpy()).map(target_to_class)), \"text\":list(target_dataset.text.values)})\n",
    "platt_cal_curve = cal.generate_calibration_curve_platt(df, code = \"L\", other_codes = [\"O\",\"P\",\"S\"])\n",
    "platt_cal_curve.plot(show_diagonal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b337b0a2-94d5-4abf-87d1-ca72a41ac12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_prevalence = cal.extrinsic_estimate(df, platt_cal_curve, code = \"L\")\n",
    "print(f'Assuming stable calibration curve -- estimated prevalence: {est_prevalence:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061933a-a777-4132-a180-12de6419267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Target dataset: number of samples in each category\")\n",
    "target_labels =list(pd.Series(target_dataset.labels.numpy()).map(target_to_class))\n",
    "print(\"L: \" + str(base_labels.count(\"L\")))\n",
    "print(\"P: \" + str(base_labels.count(\"P\")))\n",
    "print(\"S: \" + str(base_labels.count(\"S\")))\n",
    "print(\"O: \" + str(base_labels.count(\"O\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aea1b6e-b968-4552-9bcb-6b83571e3344",
   "metadata": {},
   "outputs": [],
   "source": [
    "328/(328+27+11+68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a280e95e-cbb6-48f0-a2b1-81b26e135878",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(preds.cpu().numpy()).count(0)/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da5a492-bbf5-4d90-8c38-060a646fa823",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data = pd.DataFrame(data = {\"preds\":list(pd.Series(preds.cpu().numpy()).map(target_to_class)), \"labels\":list(pd.Series(all_labels.cpu().numpy()).map(target_to_class)), \"text\":list(target_dataset.text.values)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36efa343-378a-472b-991c-acde9cae3be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "display_data[20:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf9998a-2f21-4b9f-a6b2-d844703de7fd",
   "metadata": {},
   "source": [
    "## Calibration curves for P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef4a89-dbe3-43e1-8954-3c7d3a2833bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, sharey=True, tight_layout=True)\n",
    "axs.hist(df[\"probs_P\"], bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4607f11-7f44-40b4-9775-3c92db8309bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {\"probs_L\": probs[:,0], \"probs_O\": probs[:,1], \"probs_P\": probs[:,2], \"probs_S\": probs[:,3], \"gt_label\":list(pd.Series(all_labels.cpu().numpy()).map(target_to_class)), \"text\":list(target_dataset.text.values)})\n",
    "binned_cal_curve = cal.generate_calibration_curve_binned(df, num_bin = 10, code = \"P\", other_codes = [\"O\",\"L\",\"S\"])\n",
    "binned_cal_curve.plot(show_diagonal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c14ddff-0689-4bd1-af4a-147513595813",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {\"probs_L\": probs[:,0], \"probs_O\": probs[:,1], \"probs_P\": probs[:,2], \"probs_S\": probs[:,3], \"gt_label\":list(pd.Series(all_labels.cpu().numpy()).map(target_to_class)), \"text\":list(target_dataset.text.values)})\n",
    "platt_cal_curve = cal.generate_calibration_curve_platt(df, code = \"P\", other_codes = [\"O\",\"L\",\"S\"])\n",
    "platt_cal_curve.plot(show_diagonal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81625212-9278-461c-957a-34b508c86bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_prevalence = cal.extrinsic_estimate(df, platt_cal_curve, code = \"P\")\n",
    "print(f'Assuming stable calibration curve -- estimated prevalence: {est_prevalence:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9c075d-687d-453c-bc0b-be8297482d83",
   "metadata": {},
   "source": [
    "## Calibration curves for S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d1e14-e9ff-4b10-86a5-2e19fd699246",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, sharey=True, tight_layout=True)\n",
    "axs.hist(df[\"probs_S\"], bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a7d9e-4dee-4b09-9b9b-67902faf75fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {\"probs_L\": probs[:,0], \"probs_O\": probs[:,1], \"probs_P\": probs[:,2], \"probs_S\": probs[:,3], \"gt_label\":list(pd.Series(all_labels.cpu().numpy()).map(target_to_class)), \"text\":list(target_dataset.text.values)})\n",
    "binned_cal_curve = cal.generate_calibration_curve_binned(df, num_bin = 10, code = \"S\", other_codes = [\"O\",\"P\",\"L\"])\n",
    "binned_cal_curve.plot(show_diagonal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb154e6b-0342-48b6-81f9-7d8c35d5e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {\"probs_L\": probs[:,0], \"probs_O\": probs[:,1], \"probs_P\": probs[:,2], \"probs_S\": probs[:,3], \"gt_label\":list(pd.Series(all_labels.cpu().numpy()).map(target_to_class)), \"text\":list(target_dataset.text.values)})\n",
    "platt_cal_curve = cal.generate_calibration_curve_platt(df, code = \"S\", other_codes = [\"O\",\"P\",\"L\"])\n",
    "platt_cal_curve.plot(show_diagonal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0656f-3972-4c5c-aed4-2328fcf84a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_prevalence = cal.extrinsic_estimate(df, platt_cal_curve, code = \"S\")\n",
    "print(f'Assuming stable calibration curve -- estimated prevalence: {est_prevalence:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea12914-b61f-4422-8bfb-78834d985f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf962fe8-3456-400f-9cd0-b9e7e6e8fae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
